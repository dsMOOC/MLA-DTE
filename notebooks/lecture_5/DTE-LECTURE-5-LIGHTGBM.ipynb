{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](../../data/MLU_Logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Access Samples Data Set\n",
    " \n",
    " Let's apply our boosting algorithm to a real dataset! We are going to use the __Amazon Access Samples dataset__. \n",
    " \n",
    " We download this dataset from UCI ML repository from this [link](https://archive.ics.uci.edu/ml/datasets/Amazon+Access+Samples). Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    " \n",
    "__Dataset description:__\n",
    "\n",
    "Employees need to request certain resources to fulfill their daily duties. This data consists of anonymized historical data of employee IT access requests. Data fields look like this:\n",
    " #### Column Descriptions\n",
    "\n",
    "* __ACTION__: 1 if the resource was approved, 0 if not.\n",
    "* __RESOURCE__: An ID for each resource\n",
    "* __PERSON_MGR_ID__: ID of the user's manager\n",
    "* __PERSON_ROLLUP_1__: User grouping ID\n",
    "* __PERSON_ROLLUP_2__: User grouping ID\n",
    "* __PERSON_BUSINESS_TITLE__: Title ID \n",
    "* __PERSON_JOB_FAMILY__: Job family ID \n",
    "* __PERSON_JOB_CODE__: Job code ID \n",
    "\n",
    "Our task is to build a machine learning model that can automatically provision an employee's access to company resources given employee profile information and the resource requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download and process the dataset\n",
    "\n",
    "In this section, we will download our dataset and process it. It consists of two files, we will run the following code cells to get our dataset as a single file at the end. One of the files is large (4.8GB), so make sure you have enough storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "zsh:1: command not found: wget\n"
     ]
    }
   ],
   "source": [
    "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/00216/amzn-anon-access-samples.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar -zxvf amzn-anon-access-samples.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following files:\n",
    "* __amzn-anon-access-samples-2.0.csv__: Employee profile data.\n",
    "* __amzn-anon-access-samples-history-2.0.csv__: Resource provision history\n",
    "\n",
    "Below, we first read the amzn-anon-access-samples-2.0.csv file (it is a large file) and use some employee fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'amzn-anon-access-samples-2.0.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-adf335f4b40e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpeople\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'amzn-anon-access-samples-2.0.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperson_fields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         people[row[\"PERSON_ID\"]] = [row[\"PERSON_MGR_ID\"], row[\"PERSON_ROLLUP_1\"],\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'amzn-anon-access-samples-2.0.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "\n",
    "person_fields = [\"PERSON_ID\", \"PERSON_MGR_ID\",\n",
    "                 \"PERSON_ROLLUP_1\", \"PERSON_ROLLUP_2\",\n",
    "                 \"PERSON_DEPTNAME\", \"PERSON_BUSINESS_TITLE\",\n",
    "                 \"PERSON_JOB_FAMILY\", \"PERSON_JOB_CODE\"]\n",
    "\n",
    "people = {}\n",
    "for chunk in pd.read_csv('amzn-anon-access-samples-2.0.csv', usecols = person_fields, chunksize=5000): \n",
    "    for index, row in chunk.iterrows():\n",
    "        people[row[\"PERSON_ID\"]] = [row[\"PERSON_MGR_ID\"], row[\"PERSON_ROLLUP_1\"],\n",
    "                                    row[\"PERSON_ROLLUP_2\"], row[\"PERSON_DEPTNAME\"],\n",
    "                                    row[\"PERSON_BUSINESS_TITLE\"], row[\"PERSON_JOB_FAMILY\"],\n",
    "                                    row[\"PERSON_JOB_CODE\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read the resource provision history file. Here, we will create our dataset. We will read the add access and remove access actions and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_access_data = []\n",
    "remove_access_data = []\n",
    "\n",
    "df = pd.read_csv('amzn-anon-access-samples-history-2.0.csv')\n",
    "\n",
    "# Loop through unique logins (employee ids)\n",
    "for login in df[\"LOGIN\"].unique():\n",
    "    login_df = df[df[\"LOGIN\"]==login].copy()\n",
    "    # Save actions\n",
    "    for target in login_df[\"TARGET_NAME\"].unique():\n",
    "        login_target_df = login_df[login_df[\"TARGET_NAME\"]==target]\n",
    "        unique_actions = login_target_df[\"ACTION\"].unique()\n",
    "        if((len(unique_actions)==1) and (unique_actions[0]==\"remove_access\")):\n",
    "            remove_access_data.append([0, target] + people[login])\n",
    "        elif((len(unique_actions)==1) and (unique_actions[0]==\"add_access\")):\n",
    "            add_access_data.append([1, target] + people[login])\n",
    "\n",
    "# Create random seed\n",
    "random.seed(30)\n",
    "\n",
    "# We will use only 8000 random add_access data\n",
    "add_access_data = random.sample(add_access_data, 8000)\n",
    "\n",
    "# Add them together\n",
    "data = add_access_data + remove_access_data\n",
    "\n",
    "# Let's shuffle it\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save this data so that we can use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=[\"ACTION\", \"RESOURCE\",\n",
    "                                 \"MGR_ID\", \"ROLLUP_1\",\n",
    "                                 \"ROLLUP_2\", \"DEPTNAME\",\n",
    "                                 \"BUSINESS_TITLE\", \"JOB_FAMILY\",\n",
    "                                 \"JOB_CODE\"])\n",
    "\n",
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how our data look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLLUP_1</th>\n",
       "      <th>ROLLUP_2</th>\n",
       "      <th>DEPTNAME</th>\n",
       "      <th>BUSINESS_TITLE</th>\n",
       "      <th>JOB_FAMILY</th>\n",
       "      <th>JOB_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9802</td>\n",
       "      <td>43122</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>33467</td>\n",
       "      <td>45383</td>\n",
       "      <td>11</td>\n",
       "      <td>33326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10617</td>\n",
       "      <td>36504</td>\n",
       "      <td>33416</td>\n",
       "      <td>33689</td>\n",
       "      <td>36505</td>\n",
       "      <td>41299</td>\n",
       "      <td>33430</td>\n",
       "      <td>33326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9446</td>\n",
       "      <td>35624</td>\n",
       "      <td>33316</td>\n",
       "      <td>34256</td>\n",
       "      <td>35625</td>\n",
       "      <td>41014</td>\n",
       "      <td>33461</td>\n",
       "      <td>33326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11065</td>\n",
       "      <td>34326</td>\n",
       "      <td>33299</td>\n",
       "      <td>34397</td>\n",
       "      <td>38458</td>\n",
       "      <td>38459</td>\n",
       "      <td>33678</td>\n",
       "      <td>33289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11149</td>\n",
       "      <td>40640</td>\n",
       "      <td>33283</td>\n",
       "      <td>40641</td>\n",
       "      <td>40642</td>\n",
       "      <td>40643</td>\n",
       "      <td>33291</td>\n",
       "      <td>33431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTION  RESOURCE  MGR_ID  ROLLUP_1  ROLLUP_2  DEPTNAME  BUSINESS_TITLE  \\\n",
       "0       1      9802   43122         2         3     33467           45383   \n",
       "1       1     10617   36504     33416     33689     36505           41299   \n",
       "2       1      9446   35624     33316     34256     35625           41014   \n",
       "3       1     11065   34326     33299     34397     38458           38459   \n",
       "4       1     11149   40640     33283     40641     40642           40643   \n",
       "\n",
       "   JOB_FAMILY  JOB_CODE  \n",
       "0          11     33326  \n",
       "1       33430     33326  \n",
       "2       33461     33326  \n",
       "3       33678     33289  \n",
       "4       33291     33431  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the downloaded files\n",
    "! rm amzn-anon-access-samples-2.0.csv amzn-anon-access-samples-history-2.0.csv amzn-anon-access-samples.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LightGBM\n",
    "\n",
    "Let's use LightGBM on this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[31mscikit-learn 0.20.4 has requirement scipy>=0.13.3, but you'll have scipy 0.13.0b1 which is incompatible.\u001b[0m\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/Library/Python/2.7/site-packages/scikit_learn-0.20.4.dist-info'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -q lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLLUP_1</th>\n",
       "      <th>ROLLUP_2</th>\n",
       "      <th>DEPTNAME</th>\n",
       "      <th>BUSINESS_TITLE</th>\n",
       "      <th>JOB_FAMILY</th>\n",
       "      <th>JOB_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9802</td>\n",
       "      <td>43122</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>33467</td>\n",
       "      <td>45383</td>\n",
       "      <td>11</td>\n",
       "      <td>33326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10617</td>\n",
       "      <td>36504</td>\n",
       "      <td>33416</td>\n",
       "      <td>33689</td>\n",
       "      <td>36505</td>\n",
       "      <td>41299</td>\n",
       "      <td>33430</td>\n",
       "      <td>33326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9446</td>\n",
       "      <td>35624</td>\n",
       "      <td>33316</td>\n",
       "      <td>34256</td>\n",
       "      <td>35625</td>\n",
       "      <td>41014</td>\n",
       "      <td>33461</td>\n",
       "      <td>33326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11065</td>\n",
       "      <td>34326</td>\n",
       "      <td>33299</td>\n",
       "      <td>34397</td>\n",
       "      <td>38458</td>\n",
       "      <td>38459</td>\n",
       "      <td>33678</td>\n",
       "      <td>33289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11149</td>\n",
       "      <td>40640</td>\n",
       "      <td>33283</td>\n",
       "      <td>40641</td>\n",
       "      <td>40642</td>\n",
       "      <td>40643</td>\n",
       "      <td>33291</td>\n",
       "      <td>33431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTION  RESOURCE  MGR_ID  ROLLUP_1  ROLLUP_2  DEPTNAME  BUSINESS_TITLE  \\\n",
       "0       1      9802   43122         2         3     33467           45383   \n",
       "1       1     10617   36504     33416     33689     36505           41299   \n",
       "2       1      9446   35624     33316     34256     35625           41014   \n",
       "3       1     11065   34326     33299     34397     38458           38459   \n",
       "4       1     11149   40640     33283     40641     40642           40643   \n",
       "\n",
       "   JOB_FAMILY  JOB_CODE  \n",
       "0          11     33326  \n",
       "1       33430     33326  \n",
       "2       33461     33326  \n",
       "3       33678     33289  \n",
       "4       33291     33431  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8152 entries, 0 to 8151\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   ACTION          8152 non-null   int64\n",
      " 1   RESOURCE        8152 non-null   int64\n",
      " 2   MGR_ID          8152 non-null   int64\n",
      " 3   ROLLUP_1        8152 non-null   int64\n",
      " 4   ROLLUP_2        8152 non-null   int64\n",
      " 5   DEPTNAME        8152 non-null   int64\n",
      " 6   BUSINESS_TITLE  8152 non-null   int64\n",
      " 7   JOB_FAMILY      8152 non-null   int64\n",
      " 8   JOB_CODE        8152 non-null   int64\n",
      "dtypes: int64(9)\n",
      "memory usage: 573.3 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8000\n",
       "0     152\n",
       "Name: ACTION, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"ACTION\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fix the column types below to make sure they are handled as categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data[\"ACTION\"].values\n",
    "X = data.drop(columns='ACTION')\n",
    "\n",
    "for c in X.columns:\n",
    "    X[c] = X[c].astype('category')\n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,\n",
    "                                                      y,\n",
    "                                                      test_size=0.15,\n",
    "                                                      random_state=136,\n",
    "                                                      stratify=y\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the lightGBM model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6800, number of negative: 129\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2538\n",
      "[LightGBM] [Info] Number of data points in the train set: 6929, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.981383 -> initscore=3.964865\n",
      "[LightGBM] [Info] Start training from score 3.964865\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's auc: 0.766304\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\tvalid_0's auc: 0.850851\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's auc: 0.849565\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's auc: 0.856069\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\tvalid_0's auc: 0.855181\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's auc: 0.853859\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's auc: 0.854366\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's auc: 0.853714\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's auc: 0.851775\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's auc: 0.850362\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's auc: 0.847409\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's auc: 0.846739\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's auc: 0.846105\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's auc: 0.845399\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's auc: 0.846214\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's auc: 0.845489\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[17]\tvalid_0's auc: 0.844547\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's auc: 0.842808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's auc: 0.843678\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's auc: 0.842609\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's auc: 0.842627\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's auc: 0.840181\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's auc: 0.840743\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's auc: 0.840308\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.856069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/lightgbm/engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/lightgbm/engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# Create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "\n",
    "# Let's see our parameters\n",
    "\n",
    "# boosting_type (string, optional (default='gbdt'))\n",
    "# ‘gbdt’, traditional Gradient Boosting Decision Tree.\n",
    "# ‘dart’, Dropouts meet Multiple Additive Regression Trees.\n",
    "# ‘goss’, Gradient-based One-Side Sampling.\n",
    "# ‘rf’, Random Forest.\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary', # ‘regression’ for LGBMRegressor, ‘binary’ or ‘multiclass’ for LGBMClassifier\n",
    "    'metric': ['auc'],\n",
    "    'n_estimators': 50, # We can change it, by default 100\n",
    "    'learning_rate': 0.1, # Default 0.1\n",
    "    'num_iterations': 1000, # Default 100\n",
    "    'is_unbalance': True, # Used to fix the class imbalance in the dataset\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "#Train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=20\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the overall performance on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.61      0.37        23\n",
      "           1       0.99      0.97      0.98      1200\n",
      "\n",
      "    accuracy                           0.96      1223\n",
      "   macro avg       0.63      0.79      0.67      1223\n",
      "weighted avg       0.98      0.96      0.97      1223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = gbm.predict(X_valid, num_iteration=gbm.best_iteration)\n",
    "\n",
    "print(classification_report(y_valid, np.round(y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}